{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9KyaUM5gXR3"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries and related packages\n",
        "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers==4.46.3 tokenizers==0.20.3 einops addict easydict\n",
        "!pip install flash-attn==2.7.3 --no-build-isolation\n",
        "!pip install safetensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Define the model name.\n",
        "model_name = 'deepseek-ai/DeepSeek-OCR'\n",
        "\n",
        "# Load the tokenizer.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "# Load the pre-trained model with specific configurations\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True,\n",
        "    use_safetensors=True,\n",
        "    attn_implementation=\"eager\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "# Set the model to evaluation mode and move it to the CUDA device.\n",
        "model = model.eval().cuda()"
      ],
      "metadata": {
        "id": "sWDmrP35j-n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt for the OCR task.\n",
        "prompt = \"<image>\\n<|grounding|>Convert the document to Markdown\"\n",
        "\n",
        "image_file = '/Resume.png'\n",
        "\n",
        "output_path = '/content/'\n",
        "\n",
        "# Perform inference using the model:\n",
        "res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)"
      ],
      "metadata": {
        "id": "6EiQCNBrkBdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"result.mmd\", \"r\", encoding=\"utf-8\") as f:\n",
        "    # Read the entire content of the file into the 'ocr_text' variable.\n",
        "    ocr_text = f.read()\n",
        "\n",
        "# Print the first 50 characters of the extracted text to preview the content.\n",
        "print(ocr_text[:50])"
      ],
      "metadata": {
        "id": "yA8uefLykElf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install agno"
      ],
      "metadata": {
        "id": "QjgHuAQskhQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries: os for environment variables, Agent from agno, and Gemini model wrapper.\n",
        "import os\n",
        "from agno.agent import Agent\n",
        "from agno.models.google import Gemini\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"ResumeExtractor\",\n",
        "    model=Gemini(id=\"gemini-2.0-flash-exp\", api_key=api_key),\n",
        "    description=\"You are an expert resume parser that extracts structured information from resume text.\",\n",
        "    instructions=\"Extract specific information from resume text and return it in a structured JSON format.\",\n",
        "    markdown=False,\n",
        ")\n",
        "\n",
        "try:\n",
        "\n",
        "    extraction_prompt = f\"\"\"\n",
        "Extract the following information from this resume and return it as a valid JSON object:\n",
        "\n",
        "REQUIRED FIELDS:\n",
        "1. name\n",
        "2. skills\n",
        "3. experience\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- Extract all available information accurately\n",
        "- If a field is not found, use empty string \"\" or empty array []\n",
        "- Ensure proper JSON formatting with double quotes\n",
        "- Do not include any markdown formatting or code blocks\n",
        "- Return only the JSON object, nothing else\n",
        "\n",
        "RESUME TEXT:\n",
        "{ocr_text}\n",
        "\n",
        "Extract the information now:\n",
        "\"\"\"\n",
        "    #Executing the agent\n",
        "    response = agent.run(extraction_prompt)\n",
        "\n",
        "    print(f\"\\nAgent: {response.content}\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Please try again.\")"
      ],
      "metadata": {
        "id": "lY3CDIrIkkU-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}